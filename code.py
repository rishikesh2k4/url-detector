# Common imports
from sklearn.model_selection import train_test_split
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import random
import re

%matplotlib inline

# Import Scikit-learn helper functions
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer

# Import Scikit-learn models
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB

# Import Scikit-learn metric functions
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns



print("\n### Libraries Imported ###\n")


# Load the training data
data_dir = "/content/malicious_phish 2.csv"
print("- Loading CSV Data -")
df = pd.read_csv(data_dir)

print("\n### CSV Data Loaded ###\n")

print(df)


import pandas as pd

# Load the CSV file into a DataFrame
df = pd.read_csv('/content/malicious_phish 2.csv')

# Drop rows with any NaN values
url_df = df.dropna()

# Save the cleaned DataFrame back to a CSV file
url_df.to_csv('cleaned_file.csv', index=False)

print("Rows with NaN values have been removed.")


print(url_df)

# Perform Train/Test split
test_percentage = .2

train_df, test_df = train_test_split(url_df, test_size=test_percentage, random_state=42)

labels = train_df['type']
test_labels = test_df['type']

print("\n### Split Complete ###\n")


# Print counts of each class
print("- Counting Splits -")
print("Training Samples:", len(train_df))
print("Testing Samples:", len(test_df))

# Graph counts of each class, for both training and testing
count_train_classes = pd.value_counts(train_df['type'])
count_train_classes.plot(kind='bar', fontsize=16)
plt.title("Class Count (Training)", fontsize=20)
plt.xticks(rotation='horizontal')
plt.xlabel("Class", fontsize=20)
plt.ylabel("Class Count", fontsize=20)

plt.show()

count_test_classes = pd.value_counts(test_df['type'])
count_test_classes.plot(kind='bar', fontsize=16, colormap='ocean')
plt.title("Class Count (Testing)", fontsize=20)
plt.xticks(rotation='horizontal')
plt.xlabel("Class", fontsize=20)
plt.ylabel("Class Count", fontsize=20)

plt.show()


# Define tokenizer
#   The purpose of a tokenizer is to separate the features from the raw data


def tokenizer(url):
  """Separates feature words from the raw data
  Keyword arguments:
    url ---- The full URL

  :Returns -- The tokenized words; returned as a list
  """

  # Split by slash (/) and dash (-)
  tokens = re.split('[/-]', url)

  for i in tokens:
    # Include the splits extensions and subdomains
    if i.find(".") >= 0:
      dot_split = i.split('.')

      # Remove .com and www. since they're too common
      if "com" in dot_split:
        dot_split.remove("com")
      if "www" in dot_split:
        dot_split.remove("www")

      tokens += dot_split

  return tokens

print("\n### Tokenizer defined ###\n")


# Let's see how our tokenizer changes our URLs

test_url = "ussoccer.com/News/Federation-Services/2009/06/University-Of-Miami-President-Donna-E-Shalala-Joins-Team-To-Bring-FIFA-World-Cup-To-United-States-In.aspx"
print("\n- Full URL -\n")
print(test_url)

# Tokenize test URL
print("\n- Tokenized Output -\n")
tokenized_url = tokenizer(test_url)
print(tokenized_url)


# Vectorizer the training inputs -- Takes about 30 seconds to complete
#   There are two types of vectors:
#     1. Count vectorizer
#     2. Term Frequency-Inverse Document Frequency (TF-IDF)

print("- Training Count Vectorizer -")
cVec = CountVectorizer(tokenizer=tokenizer)
count_X = cVec.fit_transform(train_df['url'])

print("- Training TF-IDF Vectorizer -")
tVec = TfidfVectorizer(tokenizer=tokenizer)
tfidf_X = tVec.fit_transform(train_df['url'])


print("\n### Vectorizing Complete ###\n")


# Manually perform term count on test_url
for i in list(dict.fromkeys(tokenized_url)):
  print("{} - {}".format(tokenized_url.count(i), i))


example_cVec = CountVectorizer(tokenizer=tokenizer)
example_X = example_cVec.fit_transform([test_url])

print("\n- Count Vectorizer (Test URL) -\n")
print(example_X)

print()
print("=" * 50)
print()

example_tVec = TfidfVectorizer(tokenizer=tokenizer)
example_X = example_tVec.fit_transform([test_url])

print("\n- TFIDF Vectorizer (Test URL) -\n")
print(example_X)


# Vectorize the testing inputs
#   Use 'transform' instead of 'fit_transform' because we've already trained our vectorizers

print("- Count Vectorizer -")
test_count_X = cVec.transform(test_df['url'])

print("- TFIDF Vectorizer -")
test_tfidf_X = tVec.transform(test_df['url'])


print("\n### Vectorizing Complete ###\n")

# Define report generator

def generate_report(cmatrix, score, creport):
  """Generates and displays graphical reports
  Keyword arguments:
    cmatrix - Confusion matrix generated by the model
    score --- Score generated by the model
    creport - Classification Report generated by the model

  :Returns -- N/A
  """

  # Generate confusion matrix heatmap
  plt.figure(figsize=(5,5))
  sns.heatmap(cmatrix,
              annot=True,
              fmt="d",
              linewidths=.5,
              square = True,
              cmap = 'Blues',
              annot_kws={"size": 16},
              xticklabels=['bad', 'good'],
              yticklabels=['bad', 'good'])

  plt.xticks(rotation='horizontal', fontsize=16)
  plt.yticks(rotation='horizontal', fontsize=16)
  plt.xlabel('Actual Label', size=20);
  plt.ylabel('Predicted Label', size=20);

  title = 'Accuracy Score: {0:.4f}'.format(score)
  plt.title(title, size = 20);

  # Display classification report and confusion matrix
  print(creport)
  plt.show()


print("\n### Report Generator Defined ###\n")

# Multinomial Naive Bayesian with TF-IDF

# Train the model
mnb_tfidf = MultinomialNB()
mnb_tfidf.fit(tfidf_X, labels)


# Test the mode (score, predictions, confusion matrix, classification report)
score_mnb_tfidf = mnb_tfidf.score(test_tfidf_X, test_labels)
predictions_mnb_tfidf = mnb_tfidf.predict(test_tfidf_X)
cmatrix_mnb_tfidf = confusion_matrix(predictions_mnb_tfidf, test_labels)
creport_mnb_tfidf = classification_report(predictions_mnb_tfidf, test_labels)

print("\n### Model Built ###\n")
generate_report(cmatrix_mnb_tfidf, score_mnb_tfidf, creport_mnb_tfidf)

# Multinomial Naive Bayesian with Count Vectorizer

# Train the model
mnb_count = MultinomialNB()
mnb_count.fit(count_X, labels)


# Test the mode (score, predictions, confusion matrix, classification report)
score_mnb_count = mnb_count.score(test_count_X, test_labels)
predictions_mnb_count = mnb_count.predict(test_count_X)
cmatrix_mnb_count = confusion_matrix(predictions_mnb_count, test_labels)
creport_mnb_count = classification_report(predictions_mnb_count, test_labels)

print("\n### Model Built ###\n")
generate_report(cmatrix_mnb_count, score_mnb_count, creport_mnb_count)



# Logistic Regression with TF-IDF

# Train the model
lgs_tfidf = LogisticRegression(solver='lbfgs')
lgs_tfidf.fit(tfidf_X, labels)


# Test the mode (score, predictions, confusion matrix, classification report)
score_lgs_tfidf = lgs_tfidf.score(test_tfidf_X, test_labels)
predictions_lgs_tfidf = lgs_tfidf.predict(test_tfidf_X)
cmatrix_lgs_tfidf = confusion_matrix(predictions_lgs_tfidf, test_labels)
creport_lgs_tfidf = classification_report(predictions_lgs_tfidf, test_labels)

print("\n### Model Built ###\n")
generate_report(cmatrix_lgs_tfidf, score_lgs_tfidf, creport_lgs_tfidf)

# Logistic Regression with Count Vectorizer

# Train the model
lgs_count = LogisticRegression(solver='lbfgs')
lgs_count.fit(count_X, labels)


# Test the mode (score, predictions, confusion matrix, classification report)
score_lgs_count = lgs_count.score(test_count_X, test_labels)
predictions_lgs_count = lgs_count.predict(test_count_X)
cmatrix_lgs_count = confusion_matrix(predictions_lgs_count, test_labels)
creport_lgs_count = classification_report(predictions_lgs_count, test_labels)

print("\n### Model Built ###\n")
generate_report(cmatrix_lgs_count, score_lgs_count, creport_lgs_count)


# Define a function to check if a given URL is malicious
def check_url(url, count_vectorizer, tfidf_vectorizer, mnb_count, mnb_tfidf, lgs_count, lgs_tfidf):
    # Vectorize the URL using both count vectorizer and TF-IDF vectorizer
    count_vec = count_vectorizer.transform([url])
    tfidf_vec = tfidf_vectorizer.transform([url])

    # Predict using Multinomial Naive Bayes with Count Vectorizer
    pred_mnb_count = mnb_count.predict(count_vec)
    print(f"Multinomial Naive Bayes (Count Vectorizer) prediction: {pred_mnb_count[0]}")

    # Predict using Multinomial Naive Bayes with TF-IDF
    pred_mnb_tfidf = mnb_tfidf.predict(tfidf_vec)
    print(f"Multinomial Naive Bayes (TF-IDF) prediction: {pred_mnb_tfidf[0]}")

    # Predict using Logistic Regression with Count Vectorizer
    pred_lgs_count = lgs_count.predict(count_vec)
    print(f"Logistic Regression (Count Vectorizer) prediction: {pred_lgs_count[0]}")

    # Predict using Logistic Regression with TF-IDF
    pred_lgs_tfidf = lgs_tfidf.predict(tfidf_vec)
    print(f"Logistic Regression (TF-IDF) prediction: {pred_lgs_tfidf[0]}")

    # Collect predictions
    predictions = {
        "Multinomial Naive Bayes (Count Vectorizer)": pred_mnb_count[0],
        "Multinomial Naive Bayes (TF-IDF)": pred_mnb_tfidf[0],
        "Logistic Regression (Count Vectorizer)": pred_lgs_count[0],
        "Logistic Regression (TF-IDF)": pred_lgs_tfidf[0]
    }

    return predictions

# Mapping function to interpret the predictions
def interpret_prediction(prediction):
    if prediction == 'benign':
        return "safe"
    else:
        return "not safe"

# After all the training code
print("\n### Ready to check URLs ###\n")

# Input URL from the user
input_url = input("Enter a URL to check: ")

# Check the URL
results = check_url(input_url, cVec, tVec, mnb_count, mnb_tfidf, lgs_count, lgs_tfidf)

# Print results
print("\n### Prediction Results ###\n")
for model, prediction in results.items():
    print(f"{model}: {interpret_prediction(prediction)}")


